# -*- coding: utf-8 -*-
"""ml_lab3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12jB7Toe69hNHhB0T3aRusQ7w_-3c08Fv
"""

# --------------------------------------------------------
# Bayesian Decision Theory using Naive Bayes (From Scratch)
# --------------------------------------------------------

import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from math import pi

# ----------------------------
# Step 1: Generate synthetic data
# ----------------------------
X, y = make_classification(
    n_samples=500,
    n_features=2,       # total number of features
    n_informative=2,    # all features are informative
    n_redundant=0,      # no redundant features
    n_classes=2,        # binary classification
    random_state=42
)

# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# ----------------------------
# Step 2: Gaussian Naive Bayes Classifier (From Scratch)
# ----------------------------
class GaussianNaiveBayes:
    def fit(self, X, y):
        """Estimate mean, variance, and prior for each class."""
        self.classes = np.unique(y)
        self.params = {}
        for c in self.classes:
            X_c = X[y == c]
            self.params[c] = {
                'mean': X_c.mean(axis=0),
                'var': X_c.var(axis=0),
                'prior': len(X_c) / len(X)
            }

    def _gaussian_pdf(self, x, mean, var):
        """Compute Gaussian Probability Density Function."""
        eps = 1e-6  # numerical stability
        coeff = 1.0 / np.sqrt(2 * pi * var + eps)
        exponent = np.exp(-((x - mean) ** 2) / (2 * var + eps))
        return coeff * exponent

    def _predict_sample(self, x):
        """Predict class for a single sample."""
        posteriors = []
        for c, params in self.params.items():
            prior = np.log(params['prior'])
            conditional = np.sum(np.log(self._gaussian_pdf(x, params['mean'], params['var'])))
            posterior = prior + conditional
            posteriors.append((c, posterior))
        return max(posteriors, key=lambda x: x[1])[0]

    def predict(self, X):
        """Predict class labels for samples in X."""
        return np.array([self._predict_sample(x) for x in X])


# ----------------------------
# Step 3: Train and Evaluate Model
# ----------------------------
nb = GaussianNaiveBayes()
nb.fit(X_train, y_train)
y_pred = nb.predict(X_test)

# Accuracy
accuracy = np.mean(y_pred == y_test)
print(f"Model Accuracy: {accuracy:.3f}\n")

# ----------------------------
# Step 4: Confusion Matrix & Classification Report
# ----------------------------
cm = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred, target_names=["Class 0", "Class 1"])

print("Confusion Matrix:")
print(cm)
print("\nClassification Report:")
print(report)